{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2\n",
    "Congratulations! You now have a running container with a notebooks server that is configured for the workshop. We now need to create a bucket and upload some images for the following exercises:\n",
    "\n",
    "## 1 Check SDK Access\n",
    "Firstly let's just check our AWS access from this notebook. Run the following code which will list the AWS buckets on this account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n",
      "[\n",
      "  {\n",
      "    Name: 'aiasaservicetrainingjune2020',\n",
      "    CreationDate: 2020-06-16T08:14:26.000Z\n",
      "  },\n",
      "  {\n",
      "    Name: 'analysis-service-dev-serverlessdeploymentbucket-uqepnh96v97e',\n",
      "    CreationDate: 2020-10-01T14:12:58.000Z\n",
      "  },\n",
      "  {\n",
      "    Name: 'crawler-service-dev-serverlessdeploymentbucket-38k8w1558dd6',\n",
      "    CreationDate: 2020-09-30T12:55:48.000Z\n",
      "  },\n",
      "  {\n",
      "    Name: 'flibblebibblebopitypoo',\n",
      "    CreationDate: 2020-06-16T07:40:00.000Z\n",
      "  },\n",
      "  {\n",
      "    Name: 'resources-dev-serverlessdeploymentbucket-ic8u5k1y3kts',\n",
      "    CreationDate: 2020-09-30T11:46:53.000Z\n",
      "  },\n",
      "  { Name: 'talkdemodata2020', CreationDate: 2020-02-16T20:37:42.000Z },\n",
      "  {\n",
      "    Name: 'ui-service-dev-serverlessdeploymentbucket-ppgfrvx9q7bs',\n",
      "    CreationDate: 2020-10-01T14:33:43.000Z\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "AWS = require('aws-sdk')\n",
    "s3 = new AWS.S3()\n",
    "console.log('test')\n",
    "s3.listBuckets({}, function(err, data) {\n",
    "  if (err) {\n",
    "    console.log(err, err.stack)\n",
    "  }\n",
    "  else {\n",
    "    console.log(data.Buckets)\n",
    "  }\n",
    "})\n",
    "$$.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Creating a Bucket\n",
    "Next, Let's create a new bucket to hold some test images. We provided a bucket name in the envionment section of docker-compose.yml. Run the code to create the bucket. If this completes successfully, you should be able to see the bucket listed by re-running the code in 1. above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BucketAlreadyOwnedByYou: Your previous request to create the named bucket succeeded and you already own it.\n",
      "    at Request.extractError (/home/dev/work/node_modules/aws-sdk/lib/services/s3.js:837:35)\n",
      "    at Request.callListeners (/home/dev/work/node_modules/aws-sdk/lib/sequential_executor.js:106:20)\n",
      "    at Request.emit (/home/dev/work/node_modules/aws-sdk/lib/sequential_executor.js:78:10)\n",
      "    at Request.emit (/home/dev/work/node_modules/aws-sdk/lib/request.js:688:14)\n",
      "    at Request.transition (/home/dev/work/node_modules/aws-sdk/lib/request.js:22:10)\n",
      "    at AcceptorStateMachine.runTo (/home/dev/work/node_modules/aws-sdk/lib/state_machine.js:14:12)\n",
      "    at /home/dev/work/node_modules/aws-sdk/lib/state_machine.js:26:10\n",
      "    at Request.<anonymous> (/home/dev/work/node_modules/aws-sdk/lib/request.js:38:9)\n",
      "    at Request.<anonymous> (/home/dev/work/node_modules/aws-sdk/lib/request.js:690:12)\n",
      "    at Request.callListeners (/home/dev/work/node_modules/aws-sdk/lib/sequential_executor.js:116:18) {\n",
      "  code: 'BucketAlreadyOwnedByYou',\n",
      "  region: 'eu-west-1',\n",
      "  time: 2020-09-29T18:19:56.382Z,\n",
      "  requestId: '147812F6FE774A3B',\n",
      "  extendedRequestId: 'W/hYYM+KO8h5BTWYV5vBEwd4dNTLJPy8e8ykJABm9u0NaCwWhIJvFb0mXyZfkpPOguMJD9R8Ipo=',\n",
      "  cfId: undefined,\n",
      "  statusCode: 409,\n",
      "  retryable: false,\n",
      "  retryDelay: 63.47060257542918\n",
      "} BucketAlreadyOwnedByYou: Your previous request to create the named bucket succeeded and you already own it.\n",
      "    at Request.extractError (/home/dev/work/node_modules/aws-sdk/lib/services/s3.js:837:35)\n",
      "    at Request.callListeners (/home/dev/work/node_modules/aws-sdk/lib/sequential_executor.js:106:20)\n",
      "    at Request.emit (/home/dev/work/node_modules/aws-sdk/lib/sequential_executor.js:78:10)\n",
      "    at Request.emit (/home/dev/work/node_modules/aws-sdk/lib/request.js:688:14)\n",
      "    at Request.transition (/home/dev/work/node_modules/aws-sdk/lib/request.js:22:10)\n",
      "    at AcceptorStateMachine.runTo (/home/dev/work/node_modules/aws-sdk/lib/state_machine.js:14:12)\n",
      "    at /home/dev/work/node_modules/aws-sdk/lib/state_machine.js:26:10\n",
      "    at Request.<anonymous> (/home/dev/work/node_modules/aws-sdk/lib/request.js:38:9)\n",
      "    at Request.<anonymous> (/home/dev/work/node_modules/aws-sdk/lib/request.js:690:12)\n",
      "    at Request.callListeners (/home/dev/work/node_modules/aws-sdk/lib/sequential_executor.js:116:18)\n"
     ]
    }
   ],
   "source": [
    "AWS = require('aws-sdk')\n",
    "s3 = new AWS.S3()\n",
    "\n",
    "let params = {\n",
    "  Bucket: process.env.MY_BUCKET_NAME\n",
    "}\n",
    "s3.createBucket(params, function(err, data) {\n",
    "  if (err) {\n",
    "    console.log(err, err.stack)\n",
    "  }\n",
    "  else {\n",
    "    console.log(data)\n",
    "  }\n",
    "})\n",
    "$$.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Upload some data\n",
    "Next lets upload some data to our bucket. There are some test images in the directory `data/images`. The code below will upload these to our newly created bucket.\n",
    "\n",
    "Note that we are cheating here a bit! The AWS SDK has a `putObject` function but this would require us to loop over the image files and call put object for each one. Instead we are creating a child process inside our container that calls the AWS CLI to run an s3 `sync` command. This will copy the files to the bucket for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Child process exited with exit code 0\n",
      "upload: ../data/images/Business_Meeting_boxed.png to s3://aiasaservicetrainingjune2020/images/Business_Meeting_boxed.png\n",
      "upload: ../data/images/celebs_boxed.png to s3://aiasaservicetrainingjune2020/images/celebs_boxed.png\n",
      "upload: ../data/images/sci-oscars_boxed.png to s3://aiasaservicetrainingjune2020/images/sci-oscars_boxed.png\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exec = require('child_process').exec\n",
    "\n",
    "const ls = exec('aws s3 sync ../data/images/ s3://$MY_BUCKET_NAME/images', function (error, stdout, stderr) {\n",
    "  if (error) {\n",
    "    console.log(error)\n",
    "  }\n",
    "  console.log(stdout)\n",
    "  console.log(stderr)\n",
    "});\n",
    "\n",
    "ls.on('exit', function (code) {\n",
    "  console.log('Child process exited with exit code ' + code)\n",
    "})\n",
    "$$.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should be able to see these images in your newly created bucket by opening the AWS web console and viewing the bucket.\n",
    "\n",
    "Next it's onto step 3!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Javascript (Node.js)",
   "language": "javascript",
   "name": "javascript"
  },
  "language_info": {
   "file_extension": ".js",
   "mimetype": "application/javascript",
   "name": "javascript",
   "version": "14.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
